我看完 **S1.0Q Batch-1 的离线 per-episode 评估**了（每个实验大约 3500–3700 个 episode）。一句话结论：

**A1（死区惩罚）是真有效；A2（撤退鼓励）基本没触发；B1a（插入门控）太激进反伤；P2b 多 seed 仍然不稳。**
更重要的是：**“吸血鬼长尾失败（跑满 1079 step 的 timeout）”还在，而且仍然主要由横向误差（lateral / y_err）驱动。**

下面是我从 episodes.csv 重新算的一张“关键指标快照”（更贴近你要打的仗：谁在减少失败长尾、谁在让系统更稳）。

| 实验               |    成功率(ep) | fail_step_share | timeout占比(steps=1079) | P(ever_dead_zone) | lateral p90 (m) | yaw p90 (deg) |
| ---------------- | ---------: | --------------: | --------------------: | ----------------: | --------------: | ------------: |
| B0 baseline      |     82.27% |          39.71% |                16.60% |            14.83% |           0.344 |         6.731 |
| **A1 dead_zone** | **84.72%** |      **35.04%** |            **14.36%** |        **13.19%** |       **0.326** |     **6.523** |
| A2 retreat       |     82.25% |          40.10% |                16.94% |            14.34% |           0.357 |         6.808 |
| B1a ins_gate     |     80.97% |          41.08% |                17.06% |            15.04% |           0.367 |         7.023 |
| D P2b s2026      |     82.71% |          39.23% |                16.27% |            14.47% |           0.343 |         7.000 |
| D P2b s7         |     80.56% |          42.52% |                17.80% |            14.97% |           0.378 |         7.068 |

（你也可以直接下载这个表：
[CSV](sandbox:/mnt/data/s1.0q_batch1_metrics_compact.csv) ｜ [Markdown](sandbox:/mnt/data/s1.0q_batch1_metrics_compact.md)）

---

## 1) A1 为什么有效？有效在哪里？

A1 的收益不是“玄学提分”，而是非常工程化地踩中了主要矛盾：

* **成功率 +2.45pp**（82.27% → 84.72%）
* **fail_step_share 下降 4.68pp**（39.71% → 35.04%）
* **timeout（1079 step）占比下降 2.25pp**（16.60% → 14.36%）
* **lateral 的尾部（p90）也确实变好**（0.344m → 0.326m）

这说明 A1 的“死区惩罚”在做两件事：
1）让一部分原本会拖到 timeout 的失败局变成成功；
2）减少进入死区的概率（或减少死区停留），从而改善横向长尾。

**它是能当新 baseline 的。**

---

## 2) A2 为什么“看起来没用”？——大概率不是方向错，是信号没被点亮

评估报告里提到训练日志 `r_retreat` 均值基本为 0，原因是死区里 `delta_insert≈0`，奖励根本没触发。

我再补一句“更像真凶”的解释：
你现在的 A2 设计很容易出现这种情况——**策略真的退出来那一步，刚好跨出 dead_zone gate，于是那一步不给奖励**；久而久之，策略学不到“退出死区是划算的”。

所以 A2 不是该扔，而是该升级成 **A2v2（能稳定触发的撤退信号）**。

---

## 3) B1a 为什么反伤？

B1a 的现象非常典型：**“上游断粮”**。

你把插入进度奖励门控得太硬（评估里写的是 `ins_floor=0.0` 这一类激进设定），结果策略在“还没对齐好”的时候，连“先靠近再修正”的动力都被剥夺了，于是：

* 成功率下滑（-1.30pp）
* fail_step_share 更差
* lateral/yaw 的尾部也更糟

这类门控不是不能做，而是要**温和**、可渐进（比如 `ins_floor=0.2` 或连续权重，而不是直接归零）。

---

## 4) P2b：多 seed 结果告诉你“别把它当新常态”

D_s2026 接近 baseline，但 D_s7 明显更差。结合你之前 S1.0P 的观察，这基本坐实了：
**P2b 的改善属于“种子运气型”，不适合作为新 baseline。**

---

## 5) 现在你真正遇到的情况（最关键）

### ① timeout 不是“5% 小尾巴”，而是 **14–18% 的大块头**

很多 episode 的长度恰好卡在 1079（最大步数），并且这些 episode **成功率是 0**。
这就是你之前说的“吸血鬼失败局”——它们对 step 统计的污染非常大。

### ② 横向误差仍然是主要瓶颈（比 yaw 更“硬”）

漏斗上一直是 `P(y<0.15m)` 低于 `P(yaw<5°)`，而且 lateral p90 仍在 0.33–0.38m 量级，远高于 0.15m 的门槛。
**不狠狠干 lateral，你的成功率会被它的尾巴锁死。**

### ③ 一个很重要的“口径校准”

从 episodes 数据看：**success 与 `max_hold_counter>=9` 几乎是同一件事**。
这意味着你之前“hold_steps=10”那套理解需要回头核对一下（很可能阈值就是 9，或者计数从 0 开始导致“9 其实是 10 步”）。这会影响你后续所有“差一口气”的判断。

---

## 6) 接下来怎么优化（我建议的 Batch-2 路线）

按“主要矛盾优先”的顺序来（这很符合历史唯物主义：先解放生产力里最卡脖子的那一环）：

1. **把 A1 立为新 baseline（先别动）**
   你需要一个稳定、可复现、已经证明能削弱长尾的地基。

2. **重做撤退机制：A2 → A2v2（必须能触发）**
   推荐两条硬改动（缺一不可）：

   * gate 用 **prev_in_dead_zone**（上一帧在死区就奖励“这一帧的退出”）
   * retreat reward 用 **窗口式的 insert 下降**（例如过去 N 步的净下降），并做 clamp，避免被刷分
     你要的不是“理论上可退”，而是“策略一进去就立刻知道退出来能赚钱”。

3. **B1 走温和路线：B1a’ / B1b（别再一刀归零）**

   * 先试 `ins_floor=0.2`（或 0.1）
   * 或用连续门控（sigma 0.15–0.20 这种量级），让策略还能“靠近—修正—再推进”

4. **在 A1 baseline 上叠加 C1：横向 delta shaping（打 lateral 尾部）**
   你现在的数据非常清楚：lateral p90 才是锁门的那根铁条。
   C1 的目标要写死：**把 lateral p90 从 ~0.33m 拉向 0.25m 甚至更低**，否则 success 很难再上台阶。

5. **新增一个你必须长期盯的核心指标：P(ep_len==max)**
   这是“长尾是否被打穿”的最直观指标；比只看均值更靠谱。

---

如果你按这条路线推进，下一轮你要期待的“胜利姿势”不是 yaw 均值又抠了 0.2°，而是：
**timeout 占比显著下降 + fail_step_share 继续下探 + lateral p90 明显收缩** —— 成功率会跟着上来，而且上得更稳、更可复现。
