# 术语小词典（给非专业读者）

本页适合：看到术语就头大的人。\n建议按需查，不需要一次全读完。

---

## 强化学习相关

### Agent（智能体）

这里可以理解成“控制叉车的程序”。它输入观测，输出动作。

### Policy（策略）

就是“控制器本体”（通常是神经网络）。\n训练的结果就是得到一个表现更好的策略。

### Observation（观测）

策略每一步能看到的信息。\n本任务里不是图像，而是“位置差、角度差、速度、插入深度”等数值向量。

### Action（动作）

策略每一步输出的控制量。\n本任务是 3 维：前进/后退、转向、升降。

### Reward（奖励）

环境对你这一步表现打的分。\n训练目标是最大化长期累积奖励。

### Episode（回合）

从一次 reset 开始，到成功/失败/超时结束的一段仿真过程。

### PPO

一种常用的强化学习算法（Proximal Policy Optimization）。\n你可以把它当成“训练策略的优化方法”，不需要懂推导也能使用。

---

## Isaac Sim / Isaac Lab 相关

### Isaac Sim

NVIDIA 的机器人仿真平台，提供物理引擎、渲染、USD 场景等能力。

### Isaac Lab

基于 Isaac Sim 的“机器人学习框架”，提供任务组织、并行环境、训练脚本、与 RL 库对接等。

### USD

场景与资产的描述格式。\n叉车与托盘的模型文件（`.usd`）就是用它存的。

### Headless

不打开图形界面运行。\n训练时通常更快、更省资源。

---

## 日志与产物相关

### checkpoint

训练过程中周期性保存的模型参数文件。\n你可以用它来回放/继续训练/导出。

### TensorBoard / wandb

训练曲线可视化工具（取决于你是否启用 logger）。

