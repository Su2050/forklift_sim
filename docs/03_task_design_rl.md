# 强化学习任务设计：动作、观测、奖励、成功判定怎么工作的？

本页适合：不太懂强化学习，但想知道“为什么要这样设奖励/观测”的读者。

你不需要会推公式；你只需要把它当成“给叉车打分的规则”。

---

## 1. 强化学习在这里做的事（用一句话说清）

你给系统一个“叉车控制器”（策略网络）。

每一步它会：

1) **看一眼状态**（观测）
2) **输出 3 个控制量**（动作）
3) 仿真前进一小步
4) 环境根据当前表现给一个**分数**（奖励）
5) 重复很多很多次

训练的目标就是：让策略学会输出能拿到更高总分的动作序列。

---

## 2. 动作空间（你能控制叉车的 3 个“旋钮”）

该任务动作维度是 3（每个都先归一化到 [-1, 1]，再按比例缩放）：

| 动作名 | 直觉含义 | 代码里怎么用 | 关键上限（默认） |
|---|---|---|---|
| `drive` | 前进/后退油门 | 设轮子角速度目标 | 20 rad/s |
| `steer` | 左/右打方向 | 设转向关节角度目标 | 0.6 rad |
| `lift` | 货叉上/下 | 设升降关节速度目标 | 0.25 m/s |

一个重要的“安全开关”：

- 当系统认为“已经插入足够深”后，会**强制把 drive/steer 置零**，让策略只做抬升。
- 这样能减少“插入后继续撞击导致奖励乱跳/把车顶翻”的情况。

---

## 3. 观测空间（策略看到了什么）

观测维度是 **13**。
核心思路：**只给任务相关的信息**，让策略知道"托盘在哪/我朝哪/我动得快不快/插入到哪了/我刚刚下了什么动作"。

主要包括：

### 3.1 托盘相对叉车的位置（2 维）

- `d_xy_r`：托盘相对叉车的 x/y 位移（在叉车自身坐标系里）
- 直觉：告诉策略“托盘在我前方还是侧边、离我多远”。

### 3.2 托盘与叉车的朝向差（2 维）

用 `cos(dyaw)` 和 `sin(dyaw)` 表示。\n这么做的好处：角度在 \( \pi \) 附近不会突然跳变（更好学）。

### 3.3 叉车的速度与转动（3 维）

- `v_xy_r`：叉车平面速度（在叉车坐标系）
- `yaw_rate`：偏航角速度（转向转得多快）

### 3.4 货叉升降关节状态（2 维）

- `lift_pos`、`lift_vel`

### 3.5 插入深度（1 维）

- `insert_norm`：插入深度 / 托盘深度（归一化）

> 插入深度怎么估算？
> 环境每步会估算一个“货叉尖端 tip”：
> 找出叉车所有刚体里，在“叉车前进方向”投影最大的那个点，当作 tip。
> 这样不用硬编码“fork tip link 名称”，对不同叉车型号更兼容。

### 3.6 上一步动作（3 维）

把上一时刻动作拼到观测里，帮助策略学习“动作变化对结果的影响”。

---

## 4. 奖励函数（核心：怎么给分）

奖励由 6 部分组成：\n你可以把它理解为"想要你做什么"和"不要你做什么"。

### 奖励公式 (见 `env.py` 第 253-292 行)

```python
rew = 0
rew += 2.0 * progress       # 插入深度增量
rew += -1.0 * lateral_err   # 横向对齐误差
rew += -0.2 * yaw_err       # 偏航角误差
rew += 1.0 * lift_delta     # 抬升高度
rew += -0.01 * action_l2    # 动作平滑性
rew += 10.0 (if success)    # 成功奖励
```

> 配置参数位于 `env_cfg.py` 第 63-69 行：`rew_progress`、`rew_align`、`rew_yaw`、`rew_lift`、`rew_success`、`rew_action_l2`

### 4.1 插入进度奖励（鼓励插进去）

不是直接奖励“插入深度”，而是奖励“插入深度的增量”：

- 如果这一小步插得更深 → **加分**
- 如果没进步或倒退 → 不加分/甚至变差

直觉：让策略持续推进，而不是卡在某个深度。

### 4.2 横向对齐惩罚（别偏太多）

- 托盘 y 与叉车 y 的差距越大 → 扣分越多

### 4.3 偏航角惩罚（别歪着插）

- 托盘朝向与叉车朝向差距越大 → 扣分越多

### 4.4 抬升奖励（插入后把托盘抬起来）

奖励货叉尖端高度相对初始高度的增量（只奖励向上的部分）。

### 4.5 动作幅度惩罚（别乱踩油门/猛打方向）

- 对动作的 L2 范数做轻微惩罚
- 直觉：让动作更平滑、更稳定。

### 4.6 成功奖励（大额 bonus）

当满足“插入 + 对齐 + 抬升 + 保持”时给一次性大额奖励。\n这会显著加速“找到终点行为”的学习。

---

## 5. 成功判定条件 (KPI)

要判定任务成功，必须**同时满足**以下所有条件，并**保持一段时间**：

| 条件 | 阈值 | 配置参数 | 说明 |
|------|------|----------|------|
| 插入深度 | >= 0.8m | `insert_fraction=2/3 × pallet_depth=1.2m` | 货叉插入托盘的深度 |
| 横向误差 | <= 0.03m | `max_lateral_err_m` | 叉车与托盘的左右偏移 |
| 偏航误差 | <= 3° | `max_yaw_err_deg` | 叉车与托盘的朝向差 |
| 抬升高度 | >= 0.12m | `lift_delta_m` | 货叉相对初始位置的抬升 |
| 保持时间 | >= 1.0s | `hold_time_s` | 满足以上条件后需持续的时间 |

> 配置参数位于 `env_cfg.py` 第 49-54 行

### 为什么要"保持一段时间"（hold）？

如果不要求保持，策略可能学会一些"碰运气"的动作：\n例如高速撞击导致插入深度瞬间超过阈值，但下一步马上弹开或倾翻。\n
加入 hold 的效果是：\n必须稳定地维持在"对齐且抬升"的状态，才算真正完成任务。

---

## 6. 你可能会关心的两个现实问题

### 6.1 为什么托盘是 kinematic（固定）？

因为这是一条“从易到难”的课程学习思路：\n先让策略学会基本动作，再逐步引入更真实的物理复杂度（托盘会被推/会滑动）。

### 6.2 为什么不用相机图像做观测？

这里用的是**状态向量**（位置/速度/角度差），更容易训练、更快、更稳定。

视觉观测（RGB/Depth）属于进阶主题，会引入感知误差与大量工程复杂度。

> **想给叉车加相机？** 请看：`docs/07_vision_input.md`（含详细迭代路线图）

---

## 7. 下一步读什么

- 想知道训练命令参数、日志目录、checkpoint 在哪：`docs/04_training_and_artifacts.md`
- 想给叉车加 RGB 相机、把输入改成图像：`docs/07_vision_input.md`

