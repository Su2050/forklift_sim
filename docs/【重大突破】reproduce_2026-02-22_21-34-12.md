# 训练复现指南：`2026-02-22_21-34-12`（s1.0w_anti_hack）

**日期：** 2026-02-22
**分支：** `exp/fix-pallet-dragging`
**复现提交：** `a7451c6` — `feat(ppo): add ClampedActorCritic and refine PPO hyperparameters`

---

## 一、训练概要

| 项目 | 值 |
|---|---|
| 奖励版本 | s1.0w_anti_hack |
| 任务 ID | `Isaac-Forklift-PalletInsertLift-Direct-v0` |
| 环境数 | 1024 |
| 最大迭代 | 2000 |
| 种子 | 42 |
| 设备 | cuda:0（NVIDIA GB10, 92GB） |
| 总训练时长 | 约 1 小时 42 分钟 |
| 日志文件 | `logs/20260222_213407_train_s1.0w_anti_hack.log` |
| Checkpoint 目录 | `IsaacLab/logs/rsl_rl/forklift_pallet_insert_lift/2026-02-22_21-34-12/` |

---

## 二、代码状态与复现步骤

### 2.1 精确的 Git 状态

训练启动时的代码状态 = 上一次提交 `aab3488` + 未提交的工作区修改。
训练结束后，这些未提交修改已合并为 `a7451c6`。

因此，**检出 `a7451c6` 即可完全复现训练时的代码状态。**

```bash
cd /home/uniubi/projects/forklift_sim
git checkout a7451c6
```

验证方式：训练目录下的 `git/IsaacLab.diff` 保存了训练启动时的 `git status` 和 `git diff` 快照，可与 `aab3488..a7451c6` 的差异对照确认一致性。

### 2.2 涉及的两个关键提交

| 提交 | 内容 | 说明 |
|---|---|---|
| `aab3488` | `fix(reward): fix sky insertion exploit and refine success logic` | 奖励 hacking 修复（Z-Gate、状态惩罚、终局优化），**训练前已提交** |
| `a7451c6` | `feat(ppo): add ClampedActorCritic and refine PPO hyperparameters` | PPO 网络与超参数（ClampedActorCritic、entropy_coef 等），**训练时已在工作区生效，训练后提交** |

### 2.3 核心代码改动清单

相对于 `aab3488`，`a7451c6` 新增/修改了以下文件：

1. **`source/.../forklift_pallet_insert_lift/clamped_actor_critic.py`**（新增）
   - `ClampedActorCritic` 子类，clamp `log_std` 在 `[ln(0.05), ln(1.5)]`，防止 std 塌缩

2. **`source/.../forklift_pallet_insert_lift/__init__.py`**（修改）
   - 将 `ClampedActorCritic` 注入 `rsl_rl.modules` 命名空间

3. **`source/.../forklift_pallet_insert_lift/agents/rsl_rl_ppo_cfg.py`**（修改）
   - `class_name` → `rsl_rl.modules.ClampedActorCritic`
   - `init_noise_std` → `0.5`（原 1.0）
   - `noise_std_type` → `log`（原 scalar）
   - `entropy_coef` → `0.0005`（原 0.005）
   - `desired_kl` → `0.008`（原 0.01）

4. **`source/.../direct/__init__.py`**（修改）
   - 添加 `from . import forklift_pallet_insert_lift` 导入

---

## 三、训练命令

```bash
cd /home/uniubi/projects/forklift_sim/IsaacLab

nohup bash isaaclab.sh -p scripts/reinforcement_learning/rsl_rl/train.py \
  --task Isaac-Forklift-PalletInsertLift-Direct-v0 \
  --headless --num_envs 1024 --max_iterations 2000 \
  > /home/uniubi/projects/forklift_sim/logs/$(date +%Y%m%d_%H%M%S)_train_s1.0w_anti_hack.log 2>&1 &
```

注意：此命令**不含** `--resume`，是从零开始的全新训练。

---

## 四、训练参数快照

训练参数由 RSL-RL 自动保存在 `params/` 目录下：

### 4.1 Agent 参数（`params/agent.yaml`）

```yaml
seed: 42
device: cuda:0
num_steps_per_env: 64
max_iterations: 2000
save_interval: 50
experiment_name: forklift_pallet_insert_lift
clip_actions: 1.0
policy:
  class_name: rsl_rl.modules.ClampedActorCritic
  init_noise_std: 0.5
  noise_std_type: log
  actor_obs_normalization: true
  critic_obs_normalization: true
  actor_hidden_dims: [256, 256, 128]
  critic_hidden_dims: [256, 256, 128]
  activation: elu
algorithm:
  class_name: PPO
  num_learning_epochs: 5
  num_mini_batches: 4
  learning_rate: 0.0003
  schedule: adaptive
  gamma: 0.99
  lam: 0.95
  entropy_coef: 0.0005
  desired_kl: 0.008
  max_grad_norm: 1.0
  value_loss_coef: 1.0
  use_clipped_value_loss: true
  clip_param: 0.2
```

### 4.2 关键环境参数（`params/env.yaml` 摘要）

```yaml
# 仿真
episode_length_s: 36.0
decimation: 4
dt: 0.008333

# 场景
num_envs: 1024
env_spacing: 6.0

# 反作弊关键参数
max_insert_z_err: 0.4        # Z-Gate 容差（0.4m）
k_pre: 5.0                   # 空举惩罚系数（状态惩罚，非 delta）
lift_delta_m: 0.3             # 举升成功门槛（降低后）
rew_stay_still: 0.5           # 静止奖励系数

# 成功判定
max_lateral_err_m: 0.15
max_yaw_err_deg: 5.0
hold_time_s: 0.33

# 奖励系数
rew_success: 100.0
rew_success_time: 30.0
rew_timeout: -10.0
global_stall_steps: 120
rew_global_stall: -1.5

# 托盘
pallet_usd_path: .../assets/pallet_com_shifted.usd
pallet_depth_m: 2.16
pallet_mass: 45.0 kg
pallet_scale: [1.8, 1.8, 1.8]
```

---

## 五、Checkpoint 列表

每 50 个 iteration 保存一次，共 41 个 checkpoint：

```
model_0.pt, model_50.pt, model_100.pt, ..., model_1950.pt, model_1999.pt
```

最终模型：`model_1999.pt`

---

## 六、训练结果摘要（iter 1999）

| 指标 | 值 | 含义 |
|---|---|---|
| Mean reward | 15.51 | 平均回合奖励（正值，无作弊） |
| Mean episode length | 432.21 | 平均回合步数 |
| phase/frac_success_now | 1.27% | 即时成功率 |
| phase/frac_aligned | 27.54% | 对齐率 |
| diag/deep_insert_frac | 14.94% | 深插入率 |
| diag/near_success_frac | 50.20% | 接近成功率 |
| err/lift_height_mean | 0.0125m | 平均货叉高度（贴地） |
| s0/pen_premature | -0.0006 | 空举惩罚（接近零，证实无作弊） |
| err/yaw_deg_mean | 4.58° | 航向误差 |
| err/lateral_mean | 0.218m | 横向误差 |
| diag/deep_lat_bad_frac | 0.88% | 深插入时横向偏差过大比例（极低） |
| err/yaw_deg_deep_mean | 2.59° | 深插入时航向误差（精度很高） |

### 关键结论

1. **反作弊完全生效**：`pen_premature ≈ 0`，`lift_height_mean = 0.01m`，模型不再空举货叉。
2. **真实能力建立**：约 50% 的轨迹能开到托盘前方对齐，约 15% 能实现深插入，1~2.5% 能完成全流程。
3. **精度良好**：深插入时的航向误差仅 2.59°，横向偏差不良率仅 0.88%，说明模型学到了正确的对齐-插入技巧。
4. **存在提升空间**：成功率仍在 1~2.5% 波动，从"接近成功"到"完成任务"的最后一步转化率较低，需要更多训练迭代。

---

## 七、相关文档

- 奖励 hacking 诊断报告：[`docs/diagnostic_reports/reward_hacking_sky_insertion_2026-02-22.md`](diagnostic_reports/reward_hacking_sky_insertion_2026-02-22.md)
- 训练日志：`logs/20260222_213407_train_s1.0w_anti_hack.log`
- TensorBoard 事件文件：`IsaacLab/logs/rsl_rl/forklift_pallet_insert_lift/2026-02-22_21-34-12/events.out.tfevents.*`
